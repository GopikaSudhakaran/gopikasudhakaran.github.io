<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Gopika Sudhakaran</title>
<link rel="stylesheet" href="style.css">
</head>
<body>

<div class="header">
  <img src="images/profile.jpg" class="profile-pic">
  <div class="title-block">
    <h1>Gopika Sudhakaran</h1>
    <h2>PhD Candidate in Visual Inference Lab and AIML Lab, TU Darmstadt</h2>
    <p>
      <a href="https://github.com/GopikaSudhakaran">GitHub</a> ·
      <a href="https://www.linkedin.com/in/gopika-sudhakaran-7a289755/">LinkedIn</a> ·
      <a href="https://scholar.google.com/citations?user=QZS6FjoAAAAJ&hl=en">Google Scholar</a> ·
      gopika (dot) sudhakaran (at) tu-darmstadt (dot) de
    </p>
  </div>
</div>

<section>
<h3>About Me</h3>
<p>I am a PhD candidate at TU Darmstadt in the Visual Inference Lab (Stefan Roth)
and the AIML Lab (Kristian Kersting). My research focuses on vision–language models, scene understanding, and structured reasoning. Currently, I am expanding this work into Neuro-Symbolic AI for embodied agents, investigating how to integrate open-vocabulary perception with logic to achieve robust generalization in out-of-distribution (OOD) scenarios.</p>
</section>

<section>
<h3>Research Interests</h3>
<ul>
  <li>Vision–Language Models (VLMs)</li>
  <li>Scene Graphs & Structured Reasoning</li>
  <li>Neuro-Symbolic AI</li>
  <li>Embodied Agents</li>
  <li>Active Learning & Data-Efficient Learning</li>
</ul>
</section>

<section>
<h3>Publications</h3>

<p><b>ART: Adaptive Relation Tuning for Generalized Relation Prediction</b><br>
Gopika Sudhakaran, Hikaru Shindo, Patrick Schramowski, Simone Schaub-Meyer, Kristian Kersting, Stefan Roth<br>
ICCV 2025 — better OOD relation prediction with active-learning-inspired training<br>
<a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Sudhakaran_ART_Adaptive_Relation_Tuning_for_Generalized_Relation_Prediction_ICCV_2025_paper.pdf">PDF</a> ·
<a href="https://github.com/visinf/ART">Code</a> ·
<a href="https://www.youtube.com/watch?v=mqZXhgAA52w&t=2s">Video</a>
</p>

<p><b>DeiSAM: Segment Anything with Deictic Prompting</b><br>
Hikaru Shindo, Manuel Brack, Gopika Sudhakaran, Devendra Singh Dhami, Patrick Schramowski, Kristian Kersting<br>
NeurIPS 2024 — better segmentation through improved reasoning<br>
<a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/5ddcfaad1cb72ce6f1a365e8f1ecf791-Paper-Conference.pdf">PDF</a> ·
<a href="https://github.com/ml-research/deictic-segment-anything">Code</a>
</p>

<p><b>DIAGen: Semantically Diverse Image Augmentation for Few-Shot Learning</b><br>
Tobias Lingenberg, Markus Reuter, Gopika Sudhakaran, Dominik Gojny, Stefan Roth, Simone Schaub-Meyer<br>
GCPR 2024 — improved few-shot robustness<br>
<a href="https://arxiv.org/pdf/2408.14584">PDF</a> ·
<a href="https://github.com/visinf/DIAGen">Code</a>
</p>

<p><b>Vision Relation Transformer for Unbiased Scene Graph Generation</b><br>
Gopika Sudhakaran, Devendra Singh Dhami, Kristian Kersting, Stefan Roth<br>
ICCV 2023 — long-tail SGG gains via debiased relations<br>
<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf">PDF</a> ·
<a href="https://github.com/visinf/veto">Code</a> ·
<a href="https://www.youtube.com/watch?v=N4YqmfDY-t0">Video</a>
</p>
</section>

<section>
<h3>Education</h3>

<p><b>PhD in Computer Science (CV and AI/ML)</b><br>
TU Darmstadt, Germany · Oct 2021 – Present<br>
Advisors: Prof. Stefan Roth & Prof. Kristian Kersting<br>
Research: vision–language models, scene understanding and reasoning.
</p>

<p><b>M.Sc. in Data Analytics</b><br>
University of Hildesheim, Germany · Apr 2019 – Aug 2021<br>
Final grade: 1.2<br>
Master Thesis (Bosch Corporate Research): Learning to Active Learn for Pedestrian Detection (Grade: 1.0)
</p>

<p><b>B.E. in Computer Science & Engineering</b><br>
PSG College of Technology, India · Jul 2011 – May 2015<br>
Final grade: 8.3/10<br>
Bachelor Thesis (McKinsey & Company): Internal tool estimating success of transformation projects (Grade: 10/10)
</p>
</section>

<section>
<h3>Work Experience</h3>

<p><b>Research Intern — Bosch Corporate Research</b><br>
Renningen, Germany · Jan 2021 – Jun 2021<br>
Worked on “Learning to Active Learn” for pedestrian detection, performing calibration and robustness evaluation on real-world datasets.</p>

<p><b>Machine Learning Intern, Highly Automated Driving — Bosch GmbH</b><br>
Abstatt, Germany · May 2020 – Oct 2020<br>
Analyzed adversarial robustness of deep models for automated driving, implementing SOTA attack methods (PGD, FGSM, LaVAN) on real and synthetic video data.</p>

<p><b>Research Assistant — University of Hildesheim</b><br>
Hildesheim, Germany · Oct 2019 – Apr 2020<br>
Worked on object detection and similarity retrieval in large cartoon/sketch datasets using Siamese and ResNet-based methods.</p>

<p><b>Data Analyst — McKinsey & Company</b><br>
Chennai, India · Jul 2015 – Aug 2018<br>
Developed product recommendation tools, cross-sell forecasting models, KPI tracking systems, and analytics modules for global financial clients.</p>

<p><b>Data Analyst Intern — McKinsey & Company</b><br>
Chennai, India · Dec 2014 – May 2015</p>

</section>

</body>
</html>
